"""
AALabelPP - Generaci√≥n de Embeddings Vectoriales
Vectorizaci√≥n de art√≠culos normativos para b√∫squeda sem√°ntica RAG

Fecha: 2025-12-14
Versi√≥n: 1.0
"""

import sys
import os
from pathlib import Path
from typing import List, Optional, Dict
from dataclasses import dataclass
from datetime import datetime
import numpy as np
from tqdm import tqdm

# ML/NLP
import torch
from sentence_transformers import SentenceTransformer

# Database
sys.path.append(str(Path(__file__).parent.parent))
from database.db_config import get_db_session, DatabaseEngine
from database.models import ArticuloNormativo, EmbeddingVectorial, DocumentoNormativo

# ============================================================================
# CONFIGURACI√ìN DE MODELOS
# ============================================================================

MODELOS_DISPONIBLES = {
    'multilingual-mpnet': {
        'nombre': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
        'dimension': 768,
        'descripcion': 'Multiling√ºe, balanceado calidad/velocidad',
        'velocidad': 'media',
        'calidad': 'alta',
        'recomendado': True
    },
    'multilingual-minilm': {
        'nombre': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'dimension': 384,
        'descripcion': 'Multiling√ºe, r√°pido, liviano',
        'velocidad': 'r√°pida',
        'calidad': 'media',
        'recomendado': False
    },
    'spanish-roberta': {
        'nombre': 'hiiamsid/sentence_similarity_spanish_es',
        'dimension': 768,
        'descripcion': 'Especializado en espa√±ol',
        'velocidad': 'media',
        'calidad': 'alta',
        'recomendado': True
    },
    'labse': {
        'nombre': 'sentence-transformers/LaBSE',
        'dimension': 768,
        'descripcion': 'Language-agnostic BERT, 109 idiomas',
        'velocidad': 'lenta',
        'calidad': 'muy alta',
        'recomendado': False
    }
}

# Modelo por defecto
MODELO_DEFAULT = 'multilingual-mpnet'


# ============================================================================
# DATACLASSES
# ============================================================================

@dataclass
class EmbeddingGenerado:
    """Resultado de generaci√≥n de embedding"""
    articulo_id: int
    embedding: np.ndarray
    tiempo_generacion: float
    modelo: str
    dimension: int


# ============================================================================
# GENERADOR DE EMBEDDINGS
# ============================================================================

class EmbeddingGenerator:
    """Generador de embeddings con m√∫ltiples modelos"""
    
    def __init__(self, modelo_nombre: str = MODELO_DEFAULT):
        """Inicializar generador
        
        Args:
            modelo_nombre: Clave del modelo en MODELOS_DISPONIBLES
        """
        if modelo_nombre not in MODELOS_DISPONIBLES:
            raise ValueError(f"Modelo no reconocido: {modelo_nombre}")
        
        self.modelo_config = MODELOS_DISPONIBLES[modelo_nombre]
        self.modelo_nombre = modelo_nombre
        self.modelo_path = self.modelo_config['nombre']
        self.dimension = self.modelo_config['dimension']
        
        print(f"\nü§ñ Cargando modelo: {self.modelo_path}")
        print(f"   Dimensi√≥n: {self.dimension}")
        print(f"   Descripci√≥n: {self.modelo_config['descripcion']}")
        
        # Detectar dispositivo (GPU si est√° disponible)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"   Dispositivo: {self.device.upper()}")
        
        # Cargar modelo
        self.modelo = SentenceTransformer(
            self.modelo_path,
            device=self.device
        )
        
        print(f"   ‚úì Modelo cargado exitosamente")
    
    def generar_embedding(self, texto: str) -> np.ndarray:
        """Generar embedding para un texto
        
        Args:
            texto: Texto a vectorizar
            
        Returns:
            Vector numpy de embeddings
        """
        # Normalizar texto (limitar longitud)
        max_length = 512  # Tokens m√°ximos
        texto = texto[:max_length * 4]  # Aproximado (4 chars = 1 token)
        
        # Generar embedding
        embedding = self.modelo.encode(
            texto,
            convert_to_numpy=True,
            show_progress_bar=False,
            normalize_embeddings=True  # L2 normalization
        )
        
        return embedding
    
    def generar_batch(self, textos: List[str], batch_size: int = 32) -> List[np.ndarray]:
        """Generar embeddings por lotes (m√°s eficiente)
        
        Args:
            textos: Lista de textos
            batch_size: Tama√±o del lote
            
        Returns:
            Lista de embeddings
        """
        embeddings = self.modelo.encode(
            textos,
            batch_size=batch_size,
            convert_to_numpy=True,
            show_progress_bar=True,
            normalize_embeddings=True
        )
        
        return embeddings


# ============================================================================
# PROCESADOR DE ART√çCULOS
# ============================================================================

class ArticulosEmbedder:
    """Procesa art√≠culos y genera embeddings"""
    
    def __init__(self, modelo_nombre: str = MODELO_DEFAULT):
        self.generator = EmbeddingGenerator(modelo_nombre)
        self.estadisticas = {
            'total_procesados': 0,
            'nuevos': 0,
            'actualizados': 0,
            'errores': 0,
            'tiempo_total': 0
        }
    
    def obtener_articulos_pendientes(
        self,
        solo_sin_embeddings: bool = True,
        limite: Optional[int] = None
    ) -> List[ArticuloNormativo]:
        """Obtener art√≠culos que necesitan embeddings
        
        Args:
            solo_sin_embeddings: Solo art√≠culos sin embeddings del modelo actual
            limite: L√≠mite de art√≠culos (None = todos)
            
        Returns:
            Lista de art√≠culos
        """
        with get_db_session() as session:
            query = session.query(ArticuloNormativo)
            
            if solo_sin_embeddings:
                # Subconsulta: art√≠culos que ya tienen embedding de este modelo
                from sqlalchemy import exists, and_
                
                subquery = session.query(EmbeddingVectorial.articulo_id).filter(
                    and_(
                        EmbeddingVectorial.articulo_id == ArticuloNormativo.id,
                        EmbeddingVectorial.modelo_embedding == self.generator.modelo_path
                    )
                )
                
                # Filtrar art√≠culos sin embedding
                query = query.filter(~exists(subquery))
            
            if limite:
                query = query.limit(limite)
            
            articulos = query.all()
            
            # Desconectar de la sesi√≥n para evitar lazy loading issues
            for art in articulos:
                session.expunge(art)
            
            return articulos
    
    def procesar_articulo(
        self,
        articulo: ArticuloNormativo,
        actualizar_existente: bool = False
    ) -> Optional[EmbeddingGenerado]:
        """Procesar un art√≠culo individual
        
        Args:
            articulo: Art√≠culo a procesar
            actualizar_existente: Si True, actualiza embedding existente
            
        Returns:
            EmbeddingGenerado o None si falla
        """
        inicio = datetime.now()
        
        try:
            # Usar texto normalizado si existe, sino completo
            texto = articulo.texto_normalizado or articulo.texto_completo
            
            if not texto or len(texto.strip()) < 10:
                print(f"‚ö† Art√≠culo {articulo.id}: Texto insuficiente")
                return None
            
            # Generar embedding
            embedding = self.generator.generar_embedding(texto)
            
            tiempo = (datetime.now() - inicio).total_seconds()
            
            return EmbeddingGenerado(
                articulo_id=articulo.id,
                embedding=embedding,
                tiempo_generacion=tiempo,
                modelo=self.generator.modelo_path,
                dimension=len(embedding)
            )
            
        except Exception as e:
            print(f"‚úó Error procesando art√≠culo {articulo.id}: {str(e)}")
            self.estadisticas['errores'] += 1
            return None
    
    def guardar_embeddings(
        self,
        embeddings: List[EmbeddingGenerado],
        actualizar_existente: bool = False
    ):
        """Guardar embeddings en la base de datos
        
        Args:
            embeddings: Lista de embeddings generados
            actualizar_existente: Si True, actualiza existentes
        """
        with get_db_session() as session:
            for emb in embeddings:
                # Verificar si existe
                existente = session.query(EmbeddingVectorial).filter(
                    EmbeddingVectorial.articulo_id == emb.articulo_id,
                    EmbeddingVectorial.modelo_embedding == emb.modelo
                ).first()
                
                if existente:
                    if actualizar_existente:
                        existente.embedding = emb.embedding.tolist()
                        existente.fecha_generacion = datetime.utcnow()
                        existente.dimension_vector = emb.dimension
                        self.estadisticas['actualizados'] += 1
                    else:
                        continue  # Saltar
                else:
                    # Crear nuevo
                    nuevo = EmbeddingVectorial(
                        articulo_id=emb.articulo_id,
                        modelo_embedding=emb.modelo,
                        dimension_vector=emb.dimension,
                        embedding=emb.embedding.tolist(),
                        fecha_generacion=datetime.utcnow(),
                        confianza_embedding=1.0
                    )
                    session.add(nuevo)
                    self.estadisticas['nuevos'] += 1
            
            session.commit()
    
    def procesar_todos(
        self,
        batch_size: int = 32,
        guardar_cada: int = 100,
        limite: Optional[int] = None
    ):
        """Procesar todos los art√≠culos pendientes
        
        Args:
            batch_size: Tama√±o de lote para procesamiento
            guardar_cada: Guardar cada N art√≠culos
            limite: L√≠mite de art√≠culos a procesar
        """
        print("\n" + "="*80)
        print("GENERACI√ìN DE EMBEDDINGS - INICIO")
        print("="*80)
        
        inicio_total = datetime.now()
        
        # Obtener art√≠culos pendientes
        print("\nüìä Obteniendo art√≠culos pendientes...")
        articulos = self.obtener_articulos_pendientes(
            solo_sin_embeddings=True,
            limite=limite
        )
        
        if not articulos:
            print("‚úì Todos los art√≠culos ya tienen embeddings")
            return
        
        print(f"   Art√≠culos a procesar: {len(articulos)}")
        print(f"   Modelo: {self.generator.modelo_nombre}")
        print(f"   Dimensi√≥n: {self.generator.dimension}")
        
        # Procesar por lotes
        embeddings_pendientes = []
        
        print("\nüîÑ Generando embeddings...")
        
        with tqdm(total=len(articulos), desc="Procesando") as pbar:
            batch_textos = []
            batch_articulos = []
            
            for i, articulo in enumerate(articulos):
                texto = articulo.texto_normalizado or articulo.texto_completo
                
                if texto and len(texto.strip()) >= 10:
                    batch_textos.append(texto)
                    batch_articulos.append(articulo)
                
                # Procesar batch cuando est√° lleno
                if len(batch_textos) >= batch_size or i == len(articulos) - 1:
                    if batch_textos:
                        # Generar embeddings del batch
                        embeddings = self.generator.generar_batch(
                            batch_textos,
                            batch_size=batch_size
                        )
                        
                        # Crear objetos EmbeddingGenerado
                        for art, emb in zip(batch_articulos, embeddings):
                            embeddings_pendientes.append(
                                EmbeddingGenerado(
                                    articulo_id=art.id,
                                    embedding=emb,
                                    tiempo_generacion=0.0,
                                    modelo=self.generator.modelo_path,
                                    dimension=len(emb)
                                )
                            )
                        
                        # Guardar si alcanzamos el l√≠mite
                        if len(embeddings_pendientes) >= guardar_cada:
                            self.guardar_embeddings(embeddings_pendientes)
                            embeddings_pendientes = []
                        
                        batch_textos = []
                        batch_articulos = []
                
                pbar.update(1)
                self.estadisticas['total_procesados'] += 1
        
        # Guardar embeddings restantes
        if embeddings_pendientes:
            print("\nüíæ Guardando embeddings finales...")
            self.guardar_embeddings(embeddings_pendientes)
        
        # Estad√≠sticas finales
        tiempo_total = (datetime.now() - inicio_total).total_seconds()
        self.estadisticas['tiempo_total'] = tiempo_total
        
        self.imprimir_estadisticas()
    
    def imprimir_estadisticas(self):
        """Imprimir estad√≠sticas de procesamiento"""
        print("\n" + "="*80)
        print("ESTAD√çSTICAS DE GENERACI√ìN")
        print("="*80)
        
        stats = self.estadisticas
        
        print(f"\nüìä Resumen:")
        print(f"   ‚Ä¢ Total procesados: {stats['total_procesados']}")
        print(f"   ‚Ä¢ Nuevos embeddings: {stats['nuevos']}")
        print(f"   ‚Ä¢ Actualizados: {stats['actualizados']}")
        print(f"   ‚Ä¢ Errores: {stats['errores']}")
        print(f"   ‚Ä¢ Tiempo total: {stats['tiempo_total']:.2f} segundos")
        
        if stats['total_procesados'] > 0:
            promedio = stats['tiempo_total'] / stats['total_procesados']
            print(f"   ‚Ä¢ Tiempo promedio: {promedio:.3f} seg/art√≠culo")
            print(f"   ‚Ä¢ Velocidad: {1/promedio:.1f} art√≠culos/seg")


# ============================================================================
# VERIFICADOR DE EMBEDDINGS
# ============================================================================

class EmbeddingsVerificador:
    """Verifica calidad y completitud de embeddings"""
    
    @staticmethod
    def verificar_cobertura() -> Dict:
        """Verificar cobertura de embeddings"""
        with get_db_session() as session:
            from sqlalchemy import func
            
            # Total de art√≠culos
            total_articulos = session.query(
                func.count(ArticuloNormativo.id)
            ).scalar()
            
            # Art√≠culos con embeddings
            total_embeddings = session.query(
                func.count(EmbeddingVectorial.id.distinct())
            ).scalar()
            
            # Por modelo
            por_modelo = session.query(
                EmbeddingVectorial.modelo_embedding,
                func.count(EmbeddingVectorial.id)
            ).group_by(EmbeddingVectorial.modelo_embedding).all()
            
            cobertura = {
                'total_articulos': total_articulos,
                'total_embeddings': total_embeddings,
                'cobertura_pct': (total_embeddings / total_articulos * 100) if total_articulos > 0 else 0,
                'por_modelo': dict(por_modelo)
            }
            
            return cobertura
    
    @staticmethod
    def imprimir_reporte():
        """Imprimir reporte de cobertura"""
        print("\n" + "="*80)
        print("REPORTE DE EMBEDDINGS")
        print("="*80)
        
        cobertura = EmbeddingsVerificador.verificar_cobertura()
        
        print(f"\nüìä Cobertura General:")
        print(f"   ‚Ä¢ Total de art√≠culos: {cobertura['total_articulos']}")
        print(f"   ‚Ä¢ Art√≠culos con embeddings: {cobertura['total_embeddings']}")
        print(f"   ‚Ä¢ Cobertura: {cobertura['cobertura_pct']:.1f}%")
        
        if cobertura['por_modelo']:
            print(f"\nü§ñ Por Modelo:")
            for modelo, count in cobertura['por_modelo'].items():
                modelo_short = modelo.split('/')[-1]
                print(f"   ‚Ä¢ {modelo_short}: {count} embeddings")
        
        # Estad√≠sticas de dimensiones
        with get_db_session() as session:
            dimensiones = session.query(
                EmbeddingVectorial.dimension_vector,
                func.count(EmbeddingVectorial.id)
            ).group_by(EmbeddingVectorial.dimension_vector).all()
            
            if dimensiones:
                print(f"\nüìê Dimensiones:")
                for dim, count in dimensiones:
                    print(f"   ‚Ä¢ {dim}D: {count} embeddings")


# ============================================================================
# CLI
# ============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Generar embeddings vectoriales para art√≠culos normativos"
    )
    parser.add_argument(
        '--modelo',
        default=MODELO_DEFAULT,
        choices=list(MODELOS_DISPONIBLES.keys()),
        help='Modelo de embeddings a utilizar'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='Tama√±o de lote para procesamiento'
    )
    parser.add_argument(
        '--limite',
        type=int,
        help='L√≠mite de art√≠culos a procesar'
    )
    parser.add_argument(
        '--actualizar',
        action='store_true',
        help='Actualizar embeddings existentes'
    )
    parser.add_argument(
        '--verificar',
        action='store_true',
        help='Solo verificar cobertura de embeddings'
    )
    parser.add_argument(
        '--listar-modelos',
        action='store_true',
        help='Listar modelos disponibles'
    )
    
    args = parser.parse_args()
    
    # Listar modelos
    if args.listar_modelos:
        print("\n" + "="*80)
        print("MODELOS DISPONIBLES")
        print("="*80)
        for key, config in MODELOS_DISPONIBLES.items():
            recomendado = " ‚≠ê RECOMENDADO" if config['recomendado'] else ""
            print(f"\nü§ñ {key}{recomendado}")
            print(f"   Nombre: {config['nombre']}")
            print(f"   Dimensi√≥n: {config['dimension']}")
            print(f"   Velocidad: {config['velocidad']}")
            print(f"   Calidad: {config['calidad']}")
            print(f"   Descripci√≥n: {config['descripcion']}")
        return
    
    # Verificar cobertura
    if args.verificar:
        EmbeddingsVerificador.imprimir_reporte()
        return
    
    # Generar embeddings
    try:
        # Inicializar BD
        DatabaseEngine.initialize()
        
        # Crear processor
        processor = ArticulosEmbedder(modelo_nombre=args.modelo)
        
        # Procesar art√≠culos
        processor.procesar_todos(
            batch_size=args.batch_size,
            limite=args.limite
        )
        
        # Verificar resultados
        print("\n")
        EmbeddingsVerificador.imprimir_reporte()
        
        print("\n" + "="*80)
        print("‚úÖ GENERACI√ìN DE EMBEDDINGS COMPLETADA")
        print("="*80)
        print("\nüöÄ Pr√≥ximo paso: python scripts/rag_engine.py")
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
